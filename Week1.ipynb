{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Phase 1 - Ingestion and Cleaning\n",
    "\n",
    " This notebook carries out the following steps\n",
    "   1. Ingest data downloaded from the LendingClub website\n",
    "   2. Choose columns to examine and prepare the data set\n",
    "   3. Visualizes single variable summaries\n",
    "   4. Removes outliers\n",
    "   5. Output a dataset ready for later analysis\n",
    "\n",
    " Things for you to add\n",
    " - Choose 3 to 5 variables and add them to the list of variables below\n",
    " - Try visualizing the new variables and other pairs of variables\n",
    "\n",
    " Prepare your presentation. Your presentation should contain at most 6 slides.\n",
    " 1. Begin by giving an overview of the project. What is the problem you wish to solve, what are the objectives? How will you evaluate the performance of the portfolio you provide? How will you measure success? What are the business KPIs?\n",
    " 2. What variables did you select for further inspection? Why do you think they will be useful? You may support any argument with a visualization.\n",
    " 3. List any insight you gained by looking at the data visualization or any other data analysis that you perform.\n",
    " 4. List 3-5 hypothesis about which variables will be important for analysis, and how they will affect the outcome.\n",
    " 5. State your conclusions. What is the main idea you wish to convey with the presentation? Do you think the data available will be useful to solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer(x):\n",
    "    '''\n",
    "    This function returns True if x is an integer, and False otherwise\n",
    "    '''\n",
    "    try:\n",
    "        return (int(x) == float(x))\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can download the archived data for 2014 from the WayBack machine here: \n",
    "# https://web.archive.org/web/20160703081246/https://resources.lendingclub.com/LoanStats3c.csv.zip\n",
    "# For the 2012-13 data, use https://web.archive.org/web/20160703081246/https://resources.lendingclub.com/LoanStats3b.csv.zip \n",
    "# Download both zip files and unzip them.\n",
    "# Put both these unzipped files in the appropriate folder (\"../data\" below) before proceeding below.\n",
    "# The data dictionary is here: https://web.archive.org/web/20200606105339/https://resources.lendingclub.com/LCDataDictionary.xlsx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"C:\\\\Users\\\\ly266e\\\\Documents\\\\Training\\\\CMU\\\\Master\\\\Fall 2023 Mini 7\\\\Business_Analytics\\\\HW\\\\General\\\\Week_1\\\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 1 - Ingestion\n",
    " Ingest the data files from both sets, perform consistency checks, and prepare one single file for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, final\n",
    "def ingest_files(directory: str) -> Dict:\n",
    "    '''\n",
    "    This function will ingest every file in the specified directory\n",
    "    into a pandas dataframe. It will return a dictionary containing\n",
    "    these dataframes, keyed by the file name.\n",
    "    \n",
    "    We assume the directory contains files directly downloaded from\n",
    "    Lending Club, and *only* those files. Thus, we assume the files are zipped\n",
    "    (pd.read_csv can read zipped files) and we assume the first line\n",
    "    in each file needs to be skipped. \n",
    "    \n",
    "    Note that this function will read and ingest more than one file and is\n",
    "    convenient if you want to ingest data for more than one year at a time.\n",
    "    \n",
    "    Note that each file will be read *without* formatting\n",
    "    '''\n",
    "    \n",
    "    # If the directory has no trailing slash, add one\n",
    "    if directory[-1] != \"/\":\n",
    "        directory = directory + \"/\"\n",
    "    \n",
    "    all_files = os.listdir(directory)\n",
    "    output = {}\n",
    "    \n",
    "    print(\"Directory \" + directory + \" has \" + str(len(all_files)) + \" files:\")\n",
    "    for i in all_files:\n",
    "        print(\"    Reading file \" + i)\n",
    "        output[i] = pd.read_csv(directory + i, dtype = str, skiprows = 1)\n",
    "        \n",
    "        # Some of the files have \"summary\" lines that, for example\n",
    "        # read \"Total number of loans number in Policy 1: .....\"\n",
    "        # To remove those lines, find any lines with non-integer IDs\n",
    "        # and remove them\n",
    "        invalid_rows = (output[i].id.apply( lambda x : is_integer(x) == False ))\n",
    "        if invalid_rows.sum() > 0:\n",
    "            print(\"        Found \" + str(invalid_rows.sum()) + \" invalid rows which were removed\")\n",
    "            output[i] = output[i][invalid_rows == False]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the set of files we downloaded \n",
    "files_data = ingest_files(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_now = pd.concat(files_data.values()).reset_index(drop = True)\n",
    "columns = list(data_now.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of columns is: {len(columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_now.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Number of Days Past Due | Status |\n",
    "| -- | -- |\n",
    "| 0 | Current |\n",
    "| 16-120 | Late | \n",
    "| 121-150 | Default |\n",
    "| 150+ | Charged-Off |\n",
    "\n",
    "- If LendingClub has decided that the loan will not be paid off, then it is given the status of **`Charged-Off`**.\n",
    "- If the payment is delayed by more than 121 days, the loan is considered as being in **`Default`**.\n",
    "- These dynamics imply that five months after the term of each loan has ended, every loan ends in one of two LendingClub states **`fully paid`** or **`charged-off`**.\n",
    "\n",
    "\n",
    "### Suggested List of Initial Columns:\n",
    "\n",
    "- id\n",
    "- loan_amnt\n",
    "- funded_amnt\n",
    "- term\n",
    "- int_rate\n",
    "- grade\n",
    "- emp_length \n",
    "- home_ownership\n",
    "- annual_inc\n",
    "- verification_status\n",
    "- issue_d\n",
    "- loan_status\n",
    "- purpose\n",
    "- dti\n",
    "- delinq_2yrs\n",
    "- earliest_cr_line\n",
    "- open_acc\n",
    "- pub_rec\n",
    "- revol_bal\n",
    "- revol_util\n",
    "- total_pymnt\n",
    "- last_pymn_d\n",
    "- recoveries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name          | Description                                                                                     | Potential Significance for Analysis                  |\n",
    "|---------------------|-------------------------------------------------------------------------------------------------|------------------------------------------------------|\n",
    "| id                  | A unique LC assigned ID for the loan listing.                                                    | Unique identifier for loans                          |\n",
    "| loan_amnt           | The listed amount of the loan applied for by the borrower.                                       | Loan size; higher amounts might be riskier           |\n",
    "| funded_amnt         | The total amount committed to that loan at that point in time.                                   | Amount actually disbursed; may differ from requested |\n",
    "| term                | The number of payments on the loan. Values are in months and can be either 36 or 60.             | Loan term; longer terms may be riskier               |\n",
    "| int_rate            | Interest Rate on the loan.                                                                       | Cost of loan; higher rates may indicate higher risk  |\n",
    "| grade               | LC assigned loan grade.                                                                          | Overall risk assessment                              |\n",
    "| emp_length          | Employment length in years.                                                                      | Stability of income                                  |\n",
    "| home_ownership      | The home ownership status provided by the borrower.                                              | Indicator of financial stability                      |\n",
    "| annual_inc          | The self-reported annual income provided by the borrower.                                        | Ability to repay the loan                             |\n",
    "| verification_status | Indicates if income was verified by LC, not verified, or if the income source was verified.       | Trustworthiness of the borrower's reported data       |\n",
    "| issue_d             | The month the loan was funded.                                                                   | Timing for seasonality analysis                       |\n",
    "| loan_status         | Current status of the loan.                                                                      | Target variable for predictive modeling               |\n",
    "| purpose             | A category provided by the borrower for the loan request.                                        | Purpose can indicate level of risk                    |\n",
    "| dti                 | A ratio calculated using the borrowerâ€™s total monthly debt payments on the total debt obligations.| Financial stability of the borrower                   |\n",
    "| delinq_2yrs         | The number of 30+ days past-due incidences of delinquency in the borrower's credit file.         | Creditworthiness                                      |\n",
    "| earliest_cr_line    | The month the borrower's earliest reported credit line was opened.                               | Credit history length                                 |\n",
    "| open_acc            | The number of open credit lines in the borrower's credit file.                                   | Ability to manage credit                              |\n",
    "| pub_rec             | Number of derogatory public records.                                                             | Legal issues affecting creditworthiness               |\n",
    "| revol_bal           | Total credit revolving balance.                                                                  | Ongoing debt level                                    |\n",
    "| revol_util          | Revolving line utilization rate.                                                                 | Credit line utilization                               |\n",
    "| total_pymnt         | Payments received to date for the total amount funded.                                           | Repayment behavior                                    |\n",
    "| last_pymnt_d        | Last month payment was received.                                                                 | Recency of payment                                    |\n",
    "| recoveries          | Post charge-off gross recovery.                                                                  | Amount recovered after default                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_interest = ['loan_status', 'loan_amnt']\n",
    "data_now[columns_interest].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 2 - Choose Columns and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns we'll be keeping from the dataset\n",
    "cols_to_pick = ['id','loan_amnt', 'int_rate', 'grade','dti', 'loan_status']\n",
    "\n",
    "# Identify the type of each of these column\n",
    "float_cols = ['loan_amnt', 'dti']\n",
    "cat_cols = ['grade','loan_status']\n",
    "perc_cols = ['int_rate']\n",
    "date_cols = []\n",
    "\n",
    "# Ensure that we have types for every column\n",
    "assert set(cols_to_pick) - set(float_cols) - set(cat_cols) - set(perc_cols) - set(date_cols) == set([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns of interest\n",
    "final_data = data_now[cols_to_pick].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting with \" + str(len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # To do (A)\n",
    "\n",
    " Choose 3 to 5 variables and add them to the list of variables below\n",
    "\n",
    " You should consult the data description (excel) file you downloaded to understand the definition of various available columns\n",
    "\n",
    " TIP: If you added new variables, be sure to clean them as we just did for the default variables.\n",
    "\n",
    " You will have to add them to the group of the right type of variables (e.g. percentage, date, categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Typecast the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in float_cols:\n",
    "    final_data[i] = final_data[i].astype(float)\n",
    "    \n",
    "def clean_perc(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x.rstrip()[:-1])\n",
    "    \n",
    "for i in perc_cols:\n",
    "    final_data[i] = final_data[i].apply( clean_perc )\n",
    "    \n",
    "def clean_date(x):\n",
    "    if pd.isnull(x):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strptime( x, \"%b-%Y\").date()\n",
    "for i in date_cols:\n",
    "    final_data[i] = final_data[i].apply( clean_date )\n",
    "    \n",
    "for i in cat_cols:\n",
    "    final_data.loc[final_data[i].isnull(), i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3- Visualize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,4))\n",
    "def visualize_columns():\n",
    "    \n",
    "    '''\n",
    "    This function visualizes all columns\n",
    "      - Box-and-whisker plots for continuous variables\n",
    "      - Lists of distinct values for categorical columns\n",
    "      - A timeline density for dates\n",
    "    '''\n",
    "    \n",
    "    # Float columns\n",
    "    for i in float_cols + perc_cols:\n",
    "        # seaborn.boxplot(final_data[i])\n",
    "        final_data.boxplot(i)\n",
    "\n",
    "        # Print the three highest values\n",
    "        highest_vals = sorted(final_data[i], reverse=True)[:3]\n",
    "        smallest_val = min(final_data[i])\n",
    "        print(\"Top 3 Max: \", highest_vals, \"\\nMin: \", smallest_val)\n",
    "        # plt.text(smallest_val, -0.3, highest_vals[0])\n",
    "        # plt.text(smallest_val, -0.2, highest_vals[1])\n",
    "        # plt.text(smallest_val, -0.1, highest_vals[2])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    # Categorical columns \n",
    "    for i in cat_cols:\n",
    "        print(i)\n",
    "        print(str(len(set(final_data[i]))) + \" distinct values\")\n",
    "        print(final_data[i].value_counts())\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Date columns\n",
    "    for i in date_cols:\n",
    "        final_data[final_data[i].isnull() == False][i].apply(lambda x : str(x.year) +\n",
    "                                                \"-\" + str(x.month)).value_counts(ascending = True).plot()\n",
    "        plt.title(i + \" (\" + str(final_data[i].isnull().sum()) + \" null values)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_categorical_columns_px(column_name, data):\n",
    "    \"\"\"\n",
    "    Plots the bar chart for a given categorical column using Plotly Express\n",
    "    \"\"\"\n",
    "    fig = px.bar(data[column_name].value_counts().reset_index(), x='index', y=column_name, \n",
    "                 labels={'index': column_name, column_name: 'Frequency'},\n",
    "                 title=f'Bar plot of {column_name}')\n",
    "    fig.show()\n",
    "\n",
    "# Plot 'grade' and 'loan_status'\n",
    "plot_categorical_columns_px('grade', final_data)\n",
    "plot_categorical_columns_px('loan_status', final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_distribution_columns(column_name, data):\n",
    "    \"\"\"\n",
    "    Plots the distribution for a given numerical column using Plotly Express\n",
    "    \"\"\"\n",
    "    fig = px.histogram(data, x=column_name, title=f'Distribution of {column_name}')\n",
    "    fig.show()\n",
    "\n",
    "# Loop through all float and percentage columns to plot their distributions\n",
    "for col in float_cols + perc_cols:\n",
    "    plot_distribution_columns(col, final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # To do (B)\n",
    "\n",
    " Try visualizing the new variables and other pairs of variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 4 - Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are quite a few outliers, but the two most obvious\n",
    "# ones to remove are in annual_inc, revol_bal Remove these.\n",
    "n_rows = len(final_data)\n",
    "#final_data = final_data[final_data.annual_inc < 1000000]\n",
    "#final_data = final_data[final_data.revol_bal < 400000]\n",
    "final_data = final_data[final_data.dti < 200]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all loans that are too recent to have been paid off or\n",
    "# defaulted\n",
    "n_rows = len(final_data)\n",
    "final_data = final_data[final_data.loan_status.isin(['Fully Paid','Charged Off','Default'])]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only include loans issued since 2009\n",
    "# n_rows = len(final_data)\n",
    "# final_data = final_data[final_data.issue_d >= datetime.date(2009, 1, 1)]\n",
    "# print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data again\n",
    "visualize_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with null values. We allow categorical variables to be null\n",
    "# OTHER than grade, which is a particularly important categorical.\n",
    "# All non-categorical variables must be non-null, and we drop\n",
    "# rows that do not meet this requirement\n",
    "required_cols = set(cols_to_pick) - set(cat_cols) - set([\"id\"])\n",
    "required_cols.add(\"grade\")\n",
    "\n",
    "n_rows = len(final_data)\n",
    "final_data.dropna(subset = required_cols ,inplace=True)\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the columns selected will not be used directly in the model, but will be used to generate other features.\n",
    "# Create variables specifying the features that will be used\n",
    "\n",
    "# All categorical columns other than \"loan_status\" will be used as discrete features\n",
    "discrete_features = list(set(cat_cols) - set([\"loan_status\"]))\n",
    "\n",
    "# All numeric columns will be used as continuous features\n",
    "continuous_features = list(float_cols + perc_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 5 - Save a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the total_pymnt from the list of continuous features; this\n",
    "# variable is highly predictive of the outcome but is not known at\n",
    "# the time the loan is issued\n",
    "continuous_features = [i for i in continuous_features if i not in [\"total_pymnt\", \"recoveries\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the pickle\n",
    "pickle_file = \"/\".join(['.', \"PickleData\", \"clean_data.pickle\"])\n",
    "os.makedirs(os.path.dirname(pickle_file), exist_ok=True)\n",
    "pickle.dump( [final_data, discrete_features, continuous_features], open(pickle_file, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Read from Pickle if Saved\n",
    " Read data from saved pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the data and features from the pickle\n",
    "final_data, discrete_features, continuous_features = pickle.load( open( \"./PickleData/clean_data.pickle\", \"rb\" ) )\n",
    "#final_data, discrete_features, continuous_features = pickle.load( open( \"./PickleData/201213clean_data.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 6 Prepare your presentation.\n",
    "\n",
    " Your presentation should contain at most 6 slides.\n",
    "\n",
    " 1) Begin by giving an overview of the project. What is the problem you wish to solve, what are the objectives?\n",
    "\n",
    " How will you evaluate the performance of the portfolio you provide? How will you measure success?\n",
    "\n",
    " What are the business KPIs?\n",
    "\n",
    " 2) What variables did you select for further inspection? Why do you think they will be useful?\n",
    "\n",
    " You may support any argument with a visualization.\n",
    "\n",
    " 3) List any insight you gained by looking at the data visualization or any other data analysis that you perform.\n",
    "\n",
    " 4) List 3-5 hypothesis about which variables will be important for analysis, and how they will affect the outcome.\n",
    "\n",
    " 5) State your conclusions. What is the main idea you wish to convey with the presentation? Do you think the data available will be useful to solve the problem?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
